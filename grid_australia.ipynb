{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "disable_eager_execution()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU está disponível.\n"
     ]
    }
   ],
   "source": [
    "def check_gpu_availability():\n",
    "    physical_devices = tf.config.list_physical_devices('GPU')\n",
    "    if len(physical_devices) > 0:\n",
    "        print(\"GPU está disponível.\")\n",
    "    else:\n",
    "        print(\"Nenhuma GPU disponível. O código será executado na CPU.\")\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "check_gpu_availability()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window_MLP_Regressor(\n",
    "    datasetGen, layers, batch, function, iterr, learningRate, outFunc, epocas, shuffle\n",
    "):\n",
    "    window_size = int(0.3 * len(datasetGen))\n",
    "    window_inf = 0\n",
    "    window_sup = window_size\n",
    "    window = 1\n",
    "    global_error = []\n",
    "    start_time = time.time()  # Início da contagem de tempo       \n",
    "\n",
    "    while window_sup <= len(datasetGen):\n",
    "        tf.random.set_seed(0)\n",
    "\n",
    "        dadosGen = datasetGen[window_inf:window_sup]\n",
    "\n",
    "        X = pd.concat([dadosGen.shift(1), dadosGen.shift(2), dadosGen.shift(3), dadosGen.shift(4), dadosGen.shift(5)], axis=1)\n",
    "        y = pd.concat([dadosGen.shift(-5)], axis=1)\n",
    "        X.dropna(inplace=True)\n",
    "        y.dropna(subset=[\"Active Power(kWh)\"], inplace=True)\n",
    "        X = X.to_numpy()\n",
    "        y = y.to_numpy()\n",
    "        y = y.flatten()\n",
    "        X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "            X, y, test_size=0.2, shuffle=False, stratify=None\n",
    "        )\n",
    "        X_test, X_val, y_test, y_val = train_test_split(\n",
    "        X_temp, y_temp, test_size=0.5, shuffle=False, stratify=None\n",
    "        )\n",
    "\n",
    "        # Aplicando o modelo MLP Regressor\n",
    "\n",
    "        # Conferindo o lag:\n",
    "        input_sequence_length = len(X[0])\n",
    "        input_layer = tf.keras.layers.Input(shape=(input_sequence_length,))\n",
    "\n",
    "        mlp = input_layer  # Inicializar o modelo com a camada de entrada\n",
    "\n",
    "        for neurons in layers:\n",
    "            mlp = tf.keras.layers.Dense(units=neurons, activation=function)(mlp)\n",
    "            mlp = tf.keras.layers.Dropout(0.2)(mlp)\n",
    "\n",
    "        output_layer = tf.keras.layers.Dense(1, activation=outFunc)(mlp)\n",
    "\n",
    "        # Definir o modelo\n",
    "        mlp_model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "        early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_loss\", patience=iterr, verbose=1, min_delta=0.0001, mode='min'\n",
    "            ,restore_best_weights=True\n",
    "        )\n",
    "        opt = tf.keras.optimizers.Adam(\n",
    "            learning_rate=learningRate\n",
    "        )\n",
    "\n",
    "        # Compilar o modelo\n",
    "        mlp_model.compile(loss=\"mean_squared_error\", optimizer=opt)\n",
    "        history = mlp_model.fit(\n",
    "            x=X_train,\n",
    "            y=y_train,\n",
    "            batch_size=int(batch),\n",
    "            epochs=epocas,\n",
    "            verbose=1,\n",
    "            callbacks=[early_stopping_callback],\n",
    "            validation_data=(X_val,y_val),\n",
    "            shuffle=shuffle,\n",
    "            workers=-1,\n",
    "            use_multiprocessing=True,\n",
    "        )\n",
    "        print(mlp_model.summary())\n",
    "        OutputTest = mlp_model.predict(X_test,workers=-1,use_multiprocessing=True)\n",
    "        \n",
    "        # Calculo do erro local(janela)\n",
    "        local_error = [\n",
    "            ((previsto - target) ** 2) ** 0.5\n",
    "            for previsto, target in zip(OutputTest, y_test)\n",
    "        ]\n",
    "        # Concatena na lista\n",
    "        global_error += local_error\n",
    "        window_inf = window_inf + len(OutputTest)\n",
    "        window_sup = window_sup + len(OutputTest)\n",
    "        window += 1\n",
    "        K.clear_session()\n",
    "\n",
    "    rmse = np.mean(global_error)\n",
    "    std = np.std(global_error)\n",
    "\n",
    "    end_time = time.time()  # Fim da contagem de tempo\n",
    "\n",
    "    save_time = end_time - start_time  # Tempo total para salvar\n",
    "    hp_str = \"layers_{}__function_{}__batch_{}__iter_{}__LearnR_{}__outFunc_{}__time_{}__lag5\".format(\n",
    "        layers, function, batch, iterr, learningRate,outFunc,save_time\n",
    "    )\n",
    "\n",
    "    np.savetxt(\n",
    "        \"resultados_australia_5/\" + hp_str + \".csv\",\n",
    "        np.array([rmse, std]),\n",
    "        delimiter=\",\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.894613\n",
       "1    0.888422\n",
       "2    0.758117\n",
       "3    0.903145\n",
       "4    0.946578\n",
       "Name: Active Power(kWh), dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data = pd.read_csv(\"base_australia_diario.csv\")\n",
    "Data.columns = Data.columns.str.strip()\n",
    "Data_Power = Data[\"Active Power(kWh)\"].dropna()\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "data = Data_Power.values\n",
    "data = data.reshape(-1, 1)\n",
    "normalized_data = scaler.fit_transform(data)\n",
    "Data_Power = pd.Series(\n",
    "    [value for row in normalized_data for value in row], name=\"Active Power(kWh)\"\n",
    ")\n",
    "Data_Power.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_sizes = [  \n",
    "# Cami\n",
    "    # (5,5),\n",
    "    # (4,4),\n",
    "    # (3,3),\n",
    "    # (16,16),\n",
    "    # (32,32),\n",
    "    # (3, 32, 32, 16)\n",
    "# Eu\n",
    "    (3,3,3,),\n",
    "    (4,4,4,),\n",
    "    (5,10,5,),\n",
    "    (5,10,10,5),\n",
    "    (5,10,10,10,5),\n",
    "    (5,10,25,10,5),\n",
    "    (8,16,32,16,8,4,2),\n",
    "]\n",
    "activation = [\n",
    "    \"sigmoid\",\n",
    "    \"tanh\",\n",
    "    \"relu\",\n",
    "    \"elu\",\n",
    "]\n",
    "outFuncs = [\n",
    "    'linear',\n",
    "    'relu',\n",
    "    'elu'\n",
    "]\n",
    "batch_size = [32]\n",
    "n_iter_no_change = [10]\n",
    "learningRates = [0.0001, 0.001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteração:  1\n",
      "Parameters:  (3, 3, 3) sigmoid 32 10 0.0001 linear\n",
      "Train on 778 samples, validate on 98 samples\n",
      "Epoch 1/200\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "state_file = 'stateIrGen.pkl'\n",
    "try:\n",
    "    with open(state_file, 'rb') as f:\n",
    "        state = pickle.load(f)\n",
    "        last_completed_iteration = state.get('last_completed_iteration', 0)\n",
    "except FileNotFoundError:\n",
    "    state = {}\n",
    "    last_completed_iteration = 0\n",
    "for_iter = 0\n",
    "for layers in hidden_layer_sizes:\n",
    "    for function in activation:\n",
    "        for batch in batch_size:\n",
    "            for iterr in n_iter_no_change:\n",
    "                for learningRate in learningRates:\n",
    "                    for outFunc in outFuncs:\n",
    "                        # Pule iterações já concluídas\n",
    "                        if last_completed_iteration > 0:\n",
    "                            last_completed_iteration -= 1\n",
    "                            continue\n",
    "                        else:\n",
    "                            # Atualize o estado após cada iteração\n",
    "                            for_iter+= 1\n",
    "                            state['last_completed_iteration'] = for_iter\n",
    "                            with open(state_file, 'wb') as f:\n",
    "                                pickle.dump(state, f)\n",
    "                            print('iteração: ', for_iter)                            \n",
    "                            print(\n",
    "                                \"Parameters: \",\n",
    "                                layers,\n",
    "                                function,\n",
    "                                batch,\n",
    "                                iterr,\n",
    "                                learningRate,\n",
    "                                outFunc,\n",
    "                            )\n",
    "                            sliding_window_MLP_Regressor(\n",
    "                                Data_Power,\n",
    "                                layers,\n",
    "                                batch,\n",
    "                                function,\n",
    "                                iterr,\n",
    "                                learningRate,\n",
    "                                outFunc,\n",
    "                                200,\n",
    "                                False,\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hyperparameters</th>\n",
       "      <th>rmse</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [hyperparameters, rmse, std]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "\n",
    "file_list = glob(\"resultados_australia_5/*\")\n",
    "# file_list = glob(\"resultados_LOSS/*\")\n",
    "\n",
    "dict_result = {\"hyperparameters\": [], \"rmse\": [], \"std\": []}\n",
    "\n",
    "for file in file_list:\n",
    "    array = np.loadtxt(file, delimiter=\",\")\n",
    "\n",
    "    dict_result[\"hyperparameters\"].append(file.split(\"\\\\\")[-1].split(\":\")[0])\n",
    "    dict_result[\"rmse\"].append(array[0])\n",
    "    dict_result[\"std\"].append(array[1])\n",
    "\n",
    "df = pd.DataFrame(dict_result)\n",
    "df = df.sort_values(by=[\"rmse\"], ascending=True)\n",
    "# df = df.sort_values(by=[\"std\"], ascending=True)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "df.head(30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
